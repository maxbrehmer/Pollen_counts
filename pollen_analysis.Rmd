---
title: "A quantile regression analysis on the impact of climate change on the seasonal pollen release in Sweden"
author: "Max Brehmer"
date: "`r Sys.Date()`"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r, message=FALSE}
### Libraries

library(tidyverse)
library(knitr)
library(lubridate) # Calendar date functionality
library(ggridges) # Ridge plotting
library(ggplot2) # Better plots
library(quantreg) # Quantile regression modelling
library(quantreg.nonpar)
library(gdata) # Renaming objects
library(purrr)
```

```{r, message=FALSE, warning=FALSE}
source("data_wrangling.R", local = knitr::knit_global())
```

```{r, message=FALSE, warning=FALSE}
source("analysis.R", local = knitr::knit_global())
```

```{r message=FALSE, warning=FALSE}
source("models.R", local = knitr::knit_global())
```

```{r, message=FALSE, warning=FALSE}
source("qr_models.R", local = knitr::knit_global())
```

## Abstract

## Preface

## Introduction
Over the past couple of decades it has been made clear that our climate is changing rapidly in various ways. Most notably the global average temperature has risen by ca $0.2^\circ C$ per decade since the mid seventies, this constitutes an almost $1^\circ C$ increase over the past half century [@hansen2006global]. In the same time frame Sweden has also seen significant shifts in its otherwise stable and temperate climate. Several studies in recent decades draw the conclusion that plant phenology is impacted by this increase in temperature. [@van2002influence] discusses in their study of the seasonal pollen shift in the Netherlands that an advance in the start of the pollen season by 3-22 days took place in the latter third of the 20th century. Likewise this paper strives to understand what seasonal changes have occurred to the pollen season in Sweden.

As mentioned in [@lind2016pollen] the results may differ for various species of pollen. More precisely they found a stark difference in duration among arboreal plant species compared to herbaceous ones, with the former trending towards an earlier end date, while the latter was pushed to a further date and thus have a longer seasonal duration. Grass pollen, being herbaceous, is the leading cause of pollen allergy in many developed countries, meaning a lot of people suffer from these seasonal changes for an extended time [@garcia2017poaceae]. In Sweden and other parts of northern Europe however, due to differences in temperature and overall climate, the arboreal types like birch (betula) are the most common cause of pollinosis [@d2017allergenic].

Continous monitoring of pollen conducted by the Swedish Museum of Natural History (NRM) began in 1973 at the Palynological laboratory in Stockholm. Since then multiple other stations have been included in the scope of NRM's continous pollen monitoring program. As of 2022 there are 20 active stations involved [@nrm2022pollen], monitoring the release of several unique species of pollen. In this paper we consider 7 of the most allergenic species, these are the arboreal pollen of alder (alnus), birch (betula), hazel (corylus), oak (quercus), willow (salix), elm (ulmus) and the herbaceous species of grass pollen (poaceae).

In this paper we will attempt to determine the shift in dates of the start and end of the pollen season in Sweden as an effect of global warming of Earth's climate. We will consider global warming as a linear trend over the researched time period as to simplify the process of analyzing pollen patterns. We can do this as research has shown acceptable fitting of linear models over anthropogenic climate change, in regard to temperature [@hansen2006global]. An analysis will be conducted based on two separate frequentist quantile regression models, namely linear regression on empirical quantiles (EQ) and non-parametric quantile regression (QR). In a study of seasonal shifts of migratory birds [@karlsson2022comparison] perform both these methods, this paper covers the majority of the theory in regards to the construction of the statistical models. In the case of QR, we also make good use of [@takeuchi2006nonparametric] for a more in depth description of the method.

By its conclusion this research paper aims to have built a statistical model that can explain the historic shift in pollen seasons for each of the 7 species and also possesses the ability to predict expected further changes in the Swedish pollen season.

This paper begins with the `Prior research` section by presenting the findings of what we consider to be the most relevant studies of similar character to what we envisage our own research to look like.

The `Data` section is where all aspects of the data used in the research is presented. We cover these aspects in three smaller sections. Firstly `Data collection` where a light description of both the physical and digital methods used to collect the data. An extensive description of how we use the data is later presented in the section `Understanding the data`. Here the reader is granted a look at the structure of the data in the form of easily-to-read tables and which variables are to be considered in the research. We conclude the `Data` section with `Data selection` where an explanation of how we deal with missing values is conducted.

Section X `Theory` encompasses all the theoretical definitions of the methods included in this paper. In order to strengthen the significance of our results, we have used two independent methods. Linear regression on empirical quantiles and Nonparametric quantile regression. Linear regression on empirical quantiles, which we refer to as EQ, is a simple method commonly used to perform statistical analyses on different quantile levels of data, while nonparametric quantile regression (QR) is a more complex method which substitutes the conditional mean of the loss function for the conditional median and requires numerical approaches to the resulting optimization problem. Our sections on EQ and QR respectively explain the theoretical aspects of these methods, while simultaneously providing descriptions of how we have applied them in our models.

A section containing the most important results of our models is given in `Results`. This part of the paper is divided in to 2 sections for increased readability. `Plots` contains visual descriptions of how the pollen season behaves over time, for selected combinations of location and species. The remaining figures are available in the appendix. `Tables` is where the key values are presented in the form of ANOVA tables and alike. These values include regression coefficients, p-values and $R^2$ for each model. Again, as for the plots, results for all combinations of data are not presented in this section. Rather a selection of the most significant, representative and most extreme results are, while remaining tables can be found in an appendix.

The `Discussion` is the section in which we attempt to make sense of the results observed and visualized in the `Results` section. For each of the analyzed results we may be able obtain a definitive conclusion, or not, in which case a description of what we are missing for us to draw a conclusion follows. Since there are limits to what we can expect to answer in this thesis, we have set aside a section (`Further improvements`) on how, and which parts of our work can be improved upon.

This paper concludes with an `Appendix` section. Additional or complementary information which the reader may find interesting, but not vital for the results of which we form our conclusions. Each appendix is reffered to by, and refers back to a result or explanation.

## Litterature review

## Data

### Data collection
As we mentioned earlier in this paper, the monitoring of pollen in the Stockholm region is conducted by the Palynological laboratory at NRM. The laboratory in question uses a Burkard Seven Day Volumetric Spore Trap to capture pollen and spores from the air through a small entrance meant to resemble the human airways. Thus approximately 10 liters of air passes through the machine each minute, which is what humans tend to consume. In order to capture the pollen particles carried by the passing air, a sticky tape is mounted to a drum rotating at 2 mm per hour. As only a small portion of the tape is exposed to the air at each point in time, this method grants us a good indication of the volume of pollen in the passing air at any given moment. Each captured pollen is individually counted with regular intervals using microscopes. It must be noted that not all stations possess the same equipment. In particular, differing microscope sizes are used across the country. Consequently, the measured values of the pollen counts are biased towards the larger microscopes, thus showing a somewhat inaccurate representation of the true pollen counts [@nrm2022microscope] [@nrm2022pollen2]. However considering the structure of the dataset and the consequent data analysis being relativistic, for which a descriptive presentation follows in the `Data` section, this phenomenon has been ignored.

### Understanding the data
The dataset that we have at our disposal contains 5 unique variables: `date`, `station`, `name`, `count` and `factor`. Of which all but the `factor` variable are used in this research paper. We have also added a `latitude` variable since it is known that higher latitudes contribute to more extreme climate changes [alecrim2023higher]. This variable is however entirely dependent on `station`. A short description of the meaning of each variable is shown in figure ?. Data is recorded during the predicted pollen season, based on historic results.

```{r, message=FALSE}
kable(data_structure)
```

Viewing the years of availability in figure ? we conclude that not all data points are present in the data set. The stations had differing opening dates and not all species tend to be available to begin with. If no consideration for the location of said data points are made, we may observed skewed results, as the geographic distribution of monitored pollen changes over time due to availability. Thus analyzing the data in geographic categories of where they were collected is a necessary consideration.

```{r, message=FALSE}
kable(stations)
```

### Data selection
First we remove any observations with missing values in any of the columns `date`, `station` or `species` since these are fundamental parameters to perform the data analysis. For the purposes of EQ regression, the time it takes to compute the models on the entire dataset in `R` is negligible. For nonparametric quantile regression however, the computational time appears to grow very quickly with the amount of observations. This has led us to the decision to reduce the amount of content in each dataset (one dataset containing all observations of any combination of `station` and `species`) to below a fixed limit. Without reducing any data, the largest data sets contain $\approx 500 000$ observations, while some combinations of data contain considerably fewer. By testing and optimizing the models for various sizes of the datasets we decided to set the limit to $5 000$ observations per combination of data. This reduces the running time considerably, making the process of analyzing our results much easier. In order to minimize the affect this has on our results the rows must be removed uniformly over the time of year. If the number of observations in a dataset is smaller than $n \cdot 5 000$, we want to select every $n$th element and discard the rest. We can do this in `R` by using the `slice` and `bind_rows` functions from the `dplyr` package. By performing these modifications to our data, we are sure to keep the shape of the distributions the same and thus the results of the quantile regression.

### Yearly distribution of pollen
Before constructing the models, we can take a glance at what sort of results to expect from the subsequent regression analysis. In figure ? we present a ridge plot containing information about the distribution of observed pollen by date of year. The `geom_density_ridges` function from the `R` library `ggridges` is used to fit a continuous density function to what is essentially a histogram of the frequency of pollen on each date.

By looking at the average distribution from the first and last 5 years in the dataset respectively, we construct a somewhat consistent average in terms of the state of the pollen season at a given location, reducing the risk of falsely identifying outlier data as patterned occurrences. We can conclude that, in the Stockholm area, the pollen season seemed to begin earlier for all the arboreal pollen species while grass pollen (Poaceae) did not appear to show those tendencies. In general the shape of the pollen distribution was not seen to have been altered over time. A visual analysis of the distribution of yearly pollen release may suggest that the average pollen season now begins earlier by up to a month compared to 45 years ago.

```{r, message=FALSE, warning=FALSE}
ridges
```

## Theory
In this section we explain the underlying theory behind the statistical approaches used for our data analysis. We will compare the simpler "empirical quantile linear" model (EQ), as used in [karlsson2022comparison] with the supposedly more powerful method "nonparametric quantile regression" which we will refer to as QR.

By the QR approach, we estimate the response variable as the conditional median of the predictor variables, of which the median can be substituted to any other quantile of data. In the EQ method however, we use the method of ordinary least squares (OLS) to estimate the conditional mean of a subset of the predictor variables corresponding to the desired quantile level [Wikipedia]. Ordinary linear regression is the preferred method for many research purposes due to its inherent simplicity. In this research paper however, we are more interested in patterns for certain quantiles of data than the mean. To do this effectively we have conducted our research using quantile regression methods instead.

An aspect in which quantile regression performs better than linear regression is when data is not homoscedastic or normally distributed. Linear regression models perform poorly for data that is heteroscadastic and/or non-normally distributed. By estimating the conditional median however, as opposed to the mean, we get a model that yields better predictions for data with these properties. Another advantage of using quantile based methods is that one can make more accurate predictions about outliers, since nonlinear tendencies may lead to abnormal behaviors for more extreme observations, which can be more accurately accounted for when looking at quantiles rather than the mean.

All models in this paper will use `date` as the response variable, or a yearly quantile of `date`. The release date of pollen grain $i \in \{ 1,...,n \}$, where $n$ is the total amount of pollen grains released, is predicted by the models as the response $y_i$. We form a covariate vector $x_i = (1, \, t_i)$ which includes an intercept and the predictor variable $t_i \in \mathcal{T} = { \{1,...,T\}}$ which refers to the gregorian year of observation with $T$ being the amount of years monitored.

In order to make an educated analysis of the behaviour of pollen release we need a strict definition for what constitutes a pollen season. There have been many attempts by various authors to find an optimal definition for the dates of which each pollen season covers. In this paper we classify the dates within which the pollen season is deemed active by referring to the EAN definition. [bastl2018defining] The EAN database contains a lot of data on pollen release in which they define the pollen season as the date at which at least $1\%$ of the yearly pollen have been counted. By the same definition, the pollen season is said to end when 95% of all pollen has been released. A reason as to why the starting quantile level and the one at the end of the season are not symmetric (i.e. why $Q_{start} \neq 1 - Q_{end}$) may be similar to how infection transmission models tend to behave, namely that the beginning of the season tends to be very intense while the distribution decreases more slowly towards the end of the season.

When performing calculations of the arithmetic mean of a vector, we use the following formula:
$$
\bar{x} = \underset{\bar{x} \in \mathbb{R}}{\mathrm{\arg \min}} \sum_{i=1}^{n} (y_i - \bar{x})^2, 
$$

where $y_i$ and $x$ correspond to the observed...

If we instead want to calculate the arithmetic median vector, we use the absolute values between the vector of observations and the average instead of the square of these vectors. The median is thus provided by
$$
\hat{x} = \underset{\hat{x} \in \mathbb{R}}{\mathrm{\arg \min}} \sum_{i=1}^{n} |y_i - \hat{x}|^2.
$$

Furthermore, if one wants to compute the vector of observations for any given quantile $\tau$, one may use the minimization algorithm
$$
x_{\tau} = \underset{x_{\tau} \in \mathbb{R}}{\mathrm{\arg \min}} \sum_{i=1}^{n} l_{\tau}(y_i - x_{\tau}),
$$

where $l_{\tau}(y_i - \tau)$ represents the pinball loss function, first introduced by Roger Koenker in [koenker2005qr]. This is a convex, piecewise linear function which computes the deviation between the predicted quantile and the actual value of the target variable. It is defined by
$$
l_{\tau}(y_i - x_{\tau}) = 
\begin{cases}
(y_i - x_{\tau})\cdot\tau          & \text{if} \; (y_i - x_{\tau}) \geq 0 \\
(y_i - x_{\tau})\cdot(\tau -1)     & \text{if} \; (y_i - x_{\tau}) < 0.
\end{cases} \quad (?)
$$
[][][] CHATGPT [][][]
The pinball loss function is called "pinball" because it has a shape that resembles a pinball game, with a linear ramp up from the lower endpoint to the prediction and a linear ramp down from the prediction to the upper endpoint. The slope of the linear ramps is determined by the quantile level, q.

The pinball loss function penalizes underprediction more heavily than overprediction when q > 0.5, and vice versa when q < 0.5. This is because the loss function places more weight on the residuals below the predicted value for underprediction and above the predicted value for overprediction.

By minimizing the pinball loss function over a set of training examples, we can learn the parameters of a quantile regression model that can accurately predict the conditional quantiles of the target variable.

[][][] Explain arithmetic mean, median and quantiles and explain how the pinball loss function ties in to this. Later substitute the mu/tau value to x_ib in the regression analysis [][][].

### Nonparametric quantile regression
By nonparametric regression models we refer to models that do not make any parametric assumptions about the form of the conditional distribution function, the relationship between the response variable and predictor variable(s) are linear however. By applying the theory of nonparametric models to a linear predictor of the conditional median, we arrive at the basis of a nonparametric quantile regression model.

For a univariate nonparametric QR model, consider the observed response date $y_i$ of grain $i$ and the predictor variable year $t_i$ with an intercept in the $(n \times 2)$-matrix $X$.
$$
X = \begin{pmatrix}
1 & 1 & ... & 1\\
t_1 & t_2 & ... & t_n
\end{pmatrix}
$$

Let $Y_i$ be a stochastic variable corresponding to the observed value of $y_i$ with the conditional distribution function
$$
F_{Y_i|x_i}(y) = \mathbb{P}(Y_i \leq y \, | \, x_i), \quad -\infty < y < \infty \quad (?)
$$

In order to find the $\tau$-quantile of the conditional distribution of $Y_i \, | \, x_i$ we need to find the smallest value of $y$ such that the conditional cumulative distribution function is greater or equal to $\tau$.

So, for each quantile $0 < \tau < 1$ the inverse
$$
Q(\tau \, | \, x_i) = \text{inf}\{y; F_{Y_i \, | \, x_i} (y) \geq \tau \} \quad (?)
$$

of the conditional distribution function in (?) represents the conditional quantile function.

Moving forward, our model takes the form
$$
Q(\tau \, | \, X) = X \beta (\tau) + \varepsilon (\tau) \quad (?)
$$

whereby the column vector $\beta(\tau) = (\beta_0(\tau), \, \beta_t(\tau))^\top$ contains the intercept $\beta_0(\tau)$ and year as the slope $\beta_t(\tau)$ of quantile $\tau$. We define $\varepsilon(\tau)$ as a non-parameterised vector of the error terms.

An optimization problem is then constructed as to minimize the objective function in (?). In ordinary linear regression one typically uses the method of least squared errors (LSE) to find the model that leads to the lowest amount of loss of information. In our case we use the pinball loss function $l_{\tau}(\xi)$ introduced in [koenker2005qr] as a metric to determine the accuracy of a quantile estimate [takeuchi2006nonparametric]. For a more detailed description of how the pinball loss function works, see appendix (?.?). Furthermore, the pinball loss function is given by
$$
l_{\tau}(\xi) = 
\begin{cases}
\tau \xi        & \text{if} \; \xi \geq 0 \\
(\tau -1) \xi   & \text{if} \; \xi < 0
\end{cases} \quad (?)
$$
hence the resulting regression parameter estimates of the $\tau$-quantile is given by the solution to the minimization problem
$$
\beta(\tau) = \arg \min_{b \in \mathbb{R}^2} \sum_{i=1}^{n} l_{\tau}(y_i - x_ib). \quad (?)
$$

Since this function is non-differentiable at $0$, no direct solution exists. Rather we use numerical estimation methods provided in the `R` library `quantreg` [koenker2021rpackage], such as the Frisch-Newton interior point method to find the optimal point along the $\xi$-axis.

### Linear regression on emprical quantiles
Another approach we used is to perform linear regression on empirical quantiles, a statistical method that combines linear regression with quantile regression to model the relationship between a response variable and one or more predictor variables. The basic gist of EQ regression is to fit a linear regression model to the empirical quantiles of the response variable, rather than to the mean. This method is called "empirical" quantile regression because it estimates quantiles of the response variable based on the empirical distribution of the data, rather than assuming a specific distribution for the response variable.

One way to perform empirical quantile linear regression is by using an indicator function $I(\cdot)$. The indicator function is a mathematical function that takes a value as input and returns 1 if the value satisfies a certain condition and 0 otherwise. In the context of empirical quantile linear regression, the indicator function is used to define the estimation problem in terms of a set of linear programming (LP) constraints.

Rather than using the raw gregorian date $y_i$ as response variable, we predict an empirical quantile of the dates of a subset of observations. For each year $t \in \mathcal{T}$ we extract the set of observations
$$
\mathcal{Y}_{t} = \left\{ y_i : I(t_i = t) \right\} \quad (?)
$$

Let $\tau \in (0,1)$ be a quantile. For each of our sets $\mathcal{Y}$ we let $\hat{F}_{(t)}$ be the empirical distribution function formed by the elements of its set. The corresponding empirical quantile is defined as
$$
\hat{Q}_{(t)}(\tau) = \text{inf} \left\{ y \in \mathcal{Y}_{t} : \hat{F}_t(y) \geq \tau \mid \mathcal{Y}_t \neq \emptyset \right\}. \quad (?)
$$

As in the previous method we construct the $(n \times 2)$ matrix $X$ by stacking the intercept and vector of years $(1, t)$ on top of each other. For all $t \in \mathcal{T}$, we stack the quantiles into the vector of observations $Y(\tau)$. Next we formulate the linear model
$$
Y(\tau) = X\beta(\tau) + \varepsilon(\tau). \quad (?)
$$

As before $\beta = (\beta_0, \beta_t)$ defines the regression parameters for the intercept $\beta_0$ and year $\beta_t$. Recall that in the nonparametric method, no assumptions were made about the error terms. In this approach however, we assume a normal distribution of the error terms $\varepsilon(\tau) \sim N(0, \sigma^2(\tau)I_T )$, where $I_T$ is the identity matrix of rank $T$. 

The log-likelihood of the model is given by 
$$
l(\beta(\tau), \sigma^2(\tau) \mid Y(\tau), X) = \sum_{t \in \mathcal{T}} \text{log } f \left( \hat{Q}_t(\tau) \mid (X\beta(\tau))_t, \sigma^2(\tau) \right) \quad (?)
$$

So far in this approach the model grants each year $t$ the same weight, not each individual pollen. Since the amount of pollen observed each year does not remain constant. A reweighting of the log-likelihood may be conducted as to grant each pollen the same weight. To get even weighting of each pollen, we add a weight factor $w_t = \lvert \mathcal{Y}_t \rvert$ to each empirical quantile $\hat{Q}_t(\tau)$. The reweighed log-likelihood (?), takes the form
$$
l_w(\beta(\tau), \sigma^2(\tau) \mid Y(\tau), X) = \sum_{t \in \mathcal{T}} w_t \, \text{log } f \left( \hat{Q}_t(\tau) \mid (X\beta(\tau))_t, \sigma^2(\tau) \right), \quad (?)
$$

This can easily be implemented with the `weights` argument of the `lm` function where we set the weight to be $\frac{1}{\text{nr of observaitons}}$.

To proceed fitting the model, we attempt to find the maximum likelihood estimate (MLE) of $\beta(\tau)$ and $\sigma^2(\tau)$ by optimizing
$$
MLE(\beta(\tau), \sigma^2(\tau)) =  \arg \max \, l_{w}(\beta(\tau), \sigma^2(\tau) \mid Y(\tau),X) \quad (?)
$$

for a given quantile $\tau$. Since the function is continuous and twice differentiable, the solution can easily be found using conventional methods provided in the `quantreg` package.

Förklara mer i detalj och ge exempel på aritmetiskt medelvärde, median för pinball loss function istället för att ge sig på regressionen direkt.

## Results

### Results per species and location


```{r}
# EQ models
kable(head(joined_eq_1 %>% dplyr::select(Species, Location, `Coefficient (EQ)`, `P value (EQ)`, `Predicted 1973 (EQ)`, `Predicted 2023 (EQ)`), 5), caption = "Start of pollen season for different species and locations, by most significant shift to earlier dates (EQ model)")
kable(head(joined_eq_1 %>% dplyr::select(Species, Location, `Coefficient (EQ)`, `P value (EQ)`, `Predicted 1973 (EQ)`, `Predicted 2023 (EQ)`) %>% map_df(rev), 5), caption = "Start of pollen season for different species and locations, by most significant shift to later dates (EQ model)")

kable(head(joined_eq_50 %>% dplyr::select(Species, Location, `Coefficient (EQ)`, `P value (EQ)`, `Predicted 1973 (EQ)`, `Predicted 2023 (EQ)`), 5), caption = "Peak of pollen season for different species and locations, by most significant shift to earlier dates (EQ model)")
kable(head(joined_eq_50 %>% dplyr::select(Species, Location, `Coefficient (EQ)`, `P value (EQ)`, `Predicted 1973 (EQ)`, `Predicted 2023 (EQ)`) %>% map_df(rev), 5), caption = "Peak of pollen season for different species and locations, by most significant shift to later dates (EQ model)")

kable(head(joined_eq_95 %>% dplyr::select(Species, Location, `Coefficient (EQ)`, `P value (EQ)`, `Predicted 1973 (EQ)`, `Predicted 2023 (EQ)`), 5), caption = "End of pollen season for different species and locations, by most significant shift to earlier dates (EQ model)")
kable(head(joined_eq_95 %>% dplyr::select(Species, Location, `Coefficient (EQ)`, `P value (EQ)`, `Predicted 1973 (EQ)`, `Predicted 2023 (EQ)`) %>% map_df(rev), 5), caption = "End of pollen season for different species and locations, by most significant shift to later dates (EQ model)")
```


```{r}
# QR models
kable(head(joined_qr_1 %>% dplyr::select(Species, Location, `Coefficient (QR)`, `Predicted 1973 (QR)`, `Predicted 2023 (QR)`), 5), caption = "Start of pollen season for different species and locations, by most significant shift to earlier dates (QR model)")
kable(head(joined_qr_1 %>% dplyr::select(Species, Location, `Coefficient (QR)`, `Predicted 1973 (QR)`, `Predicted 2023 (QR)`) %>% map_df(rev), 5), caption = "Start of pollen season for different species and locations, by most significant shift to later dates (QR model)")

kable(head(joined_qr_50 %>% dplyr::select(Species, Location, `Coefficient (QR)`, `Predicted 1973 (QR)`, `Predicted 2023 (QR)`), 5), caption = "Peak of pollen season for different species and locations, by most significant shift to earlier dates (QR model)")
kable(head(joined_qr_50 %>% dplyr::select(Species, Location, `Coefficient (QR)`, `Predicted 1973 (QR)`, `Predicted 2023 (QR)`) %>% map_df(rev), 5), caption = "Peak of pollen season for different species and locations, by most significant shift to later dates (QR model)")

kable(head(joined_qr_95 %>% dplyr::select(Species, Location, `Coefficient (QR)`, `Predicted 1973 (QR)`, `Predicted 2023 (QR)`), 5), caption = "End of pollen season for different species and locations, by most significant shift to earlier dates (QR model)")
kable(head(joined_qr_95 %>% dplyr::select(Species, Location, `Coefficient (QR)`, `Predicted 1973 (QR)`, `Predicted 2023 (QR)`) %>% map_df(rev), 5), caption = "End of pollen season for different species and locations, by most significant shift to later dates (QR model)")
```


### Geographic influence
```{r}
ggplot(data = joined_eq_1, aes(x = Latitude, y = `Coefficient (EQ)`, colour = Species)) +
  geom_point() +
  stat_smooth(formula = y ~ x, method="lm", se=FALSE) +
  facet_wrap(~Species) +
  labs(colour = "Species", x = "Latitude", y = "Coefficient")

ggplot(data = joined_eq_50, aes(x = Latitude, y = `Coefficient (EQ)`, colour = Species)) +
  geom_point() +
  stat_smooth(formula = y ~ x, method="lm", se=FALSE) +
  facet_wrap(~Species) +
  labs(colour = "Species", x = "Latitude", y = "Coefficient")

ggplot(data = joined_eq_95, aes(x = Latitude, y = `Coefficient (EQ)`, colour = Species)) +
  geom_point() +
  stat_smooth(formula = y ~ x, method="lm", se=FALSE) +
  facet_wrap(~Species) +
  labs(colour = "Species", x = "Latitude", y = "Coefficient")
```

```{r, warning=FALSE}
# QR performance testing
QR <- rq(formula = greg_day ~ Year, data = df %>% filter(station == "Stockholm"), tau = 1:99/100)

sumQR <- summary(QR)
```

```{r, warning=FALSE}
QR_tidy <- QR %>%
  broom::tidy(se.type = "rank", conf.int = TRUE, conf.level = 0.95) %>%
  filter(!grepl("factor", term))
```

```{r, warning=FALSE}
lm <- lm(data = df %>% filter(station == "Stockholm"), formula = greg_day ~ Year)

ols <- as.data.frame(coef(lm))
ols.ci <- as.data.frame(confint(lm))
ols2 <- cbind(ols, ols.ci)
ols2 <- tibble::rownames_to_column(ols2, var="term")
```

```{r}
# Generate a sequence of quantile levels from 0.01 to 0.99
quantile_levels <- seq(0.01, 0.99, by = 0.01)

# Create an empty data frame to store the coefficient estimates and confidence intervals
lm_quantile_df_tau <- data.frame(term = character(2*length(quantile_levels)), 
                                 estimate = numeric(2*length(quantile_levels)), 
                                 conf.low = numeric(2*length(quantile_levels)), 
                                 conf.high = numeric(2*length(quantile_levels)), 
                                 tau = numeric(2*length(quantile_levels)))

# Loop through each quantile level and compute coefficient estimates and confidence intervals
for (i in seq_along(quantile_levels)) {
  tau <- quantile_levels[i]
  
  # Compute quantile for the current quantile level
  quantile_val <- quantile(df$greg_day, probs = tau)
  
  # Subset the data for the current quantile level
  quantile_data <- df %>% filter(station == "Stockholm", greg_day <= quantile_val)
  
  # Fit linear regression for the current quantile level
  lm_quantile <- lm(formula = greg_day ~ Year, data = quantile_data)
  
  # Extract coefficient estimates and confidence intervals
  lm_quantile_coef <- coef(lm_quantile)
  lm_quantile_ci <- confint(lm_quantile, level = 0.95)
  
  # Assign the results to the corresponding row in the data frame
  lm_quantile_df_tau[i+i-1, "term"] <- "(Intercept)"
  lm_quantile_df_tau[i+i-1, "estimate"] <- lm_quantile_coef[1]
  lm_quantile_df_tau[i+i-1, "conf.low"] <- lm_quantile_ci["(Intercept)", 1]
  lm_quantile_df_tau[i+i-1, "conf.high"] <- lm_quantile_ci["(Intercept)", 2]
  lm_quantile_df_tau[i+i-1, "tau"] <- tau
  
  lm_quantile_df_tau[i+i, "term"] <- "Year"
  lm_quantile_df_tau[i+i, "estimate"] <- lm_quantile_coef[2]
  lm_quantile_df_tau[i+i, "conf.low"] <- lm_quantile_ci["Year", 1]
  lm_quantile_df_tau[i+i, "conf.high"] <- lm_quantile_ci["Year", 2]
  lm_quantile_df_tau[i+i, "tau"] <- tau
}
```


```{r}
# Define colors for QR and EQ plots
qr_color <- "#512ffa"  # QR plot color
eq_color <- "#56de07"  # EQ plot color

# Create the plot
plotQR <- QR_tidy %>% 
  ggplot(aes(x=tau,y=estimate)) +
  
  # QR
  geom_line(aes(color="QR"), size = 0.5, show.legend = FALSE) + # Set color to "QR"
  geom_hline(data = ols2, aes(yintercept= `coef(lm)`), lty=1, color="#eb2a3d", size=0.5) + 
  geom_hline(aes(yintercept = 0), lty=2, color="black", size=0.5) + 
  geom_ribbon(aes(ymin=conf.low, ymax=conf.high, fill="QR"), alpha=0.25) + # Set fill to "QR"
  
  # EQ
  geom_line(data = lm_quantile_df_tau, aes(x = tau, y = estimate, group = term, color="EQ"), size = 0.5, show.legend = FALSE) + # Set color to "EQ"
  geom_ribbon(data = lm_quantile_df_tau, aes(x = tau, ymin = conf.low, ymax = conf.high, fill="EQ"), alpha = 0.25) + # Set fill to "EQ"
  
  facet_wrap(~term, scales="free", ncol=2) +
  
  # Customize legend title and labels
  labs(color = "Method", fill = "Method") +
  scale_color_manual(values = c("QR" = qr_color, "EQ" = eq_color)) +
  scale_fill_manual(values = c("QR" = qr_color, "EQ" = eq_color))

# Display the plot
plotQR
```

```{r, message=FALSE, fig.cap="Jitter plot over the yearly distribution of betula pollen in Stockholm comparing QR and EQ at the 1% quantile level"}
trend_data <- df %>% filter(station == "Stockholm", lat_name == "Betula")
trend_summarised <- df %>% group_by(Year, lat_name, station, latitude) %>%
                summarise(q1 = quantile(greg_day, prob = .01)) %>% filter(station == "Stockholm", lat_name == "Betula")

plot_trend <- ggplot() +
  geom_jitter(data = trend_data, aes(x = Year, y = greg_day)) +
  geom_quantile(data = trend_data, aes(x = Year, y = greg_day, color = "QR"), quantiles = c(0.01), size = 1) +
  geom_jitter(data = trend_summarised, aes(x = Year, y = q1, color = "EQ")) +
  geom_smooth(data = trend_summarised, method = "lm", aes(x = Year, y = q1, color = "EQ")) +
  labs(x = "Year", y = "Day") +
  scale_color_manual(name = "Method", 
                     values = c(QR = "blue", EQ = "red"), 
                     labels = c(QR = "QR", EQ = "EQ"))

plot_trend
```

In figure (?) we see the difference in fitting of both our models. The quantile regression method fits a linear model to encompass a given quantile, in this case the first 1% of yearly pollen release, below the regression line. We can observe that year 17 appears to be a heavy outlier in which the entire pollen season came significantly earlier than other years. Since the QR method tries to fit a linear trend with a specific amount of observations below it, and a large amount of these first 1% of observations are from the 17th year, the model is heavily skewed by the observations from this year and thus does not generate a good fit. EQ does not fall for this issue since we in this approach aggregate the observations from each year to a specific date value (red points) and then perform ordinary linear regression on these aggregated observations. In this case the one outlier year corresponds to only 2% of the total observations while for QR this effect appears to be well over 50%. These results explain why the confidence intervals for QR are much larger than the equivalent measure of EQ. Thus we conclude that linear regression on emprical quantiles is a more fitting approach to use in the case of estimating the yearly seasonal shift of pollen.

## Discussion

### Further improvements

## Bibliography and References

## Appendix

### Appendix 1: Translation of the latin names of pollen species
```{r, message=FALSE}
kable(translation)
```

### Appendix 2: Information about reduced data sets (ignore)
ESKILSTUNA:
  ALNUS: 45 362 / 10 < 5 000      (10)
  BETULA: 451 397 / 91 < 5 000    (91)
  CORYLUS: 3 812
  POACEAE: 48 265 / 10 < 5 000    (10)
  QUERCUS: 57 914 / 12 < 5 000    (12)
  SALIX: 31 227 / 7 < 5 000       (7)
  ULMUS: 9 779 / 2 < 5 000        (2)
  
GÖTEBORG:
  ALNUS: 33 653 / 7 < 5 000       (7)
  BETULA: 494 464 / 99 < 5 000    (99)
  CORYLUS: 3 374
  POACEAE: 74 372 / 15 < 5 000    (15)
  QUERCUS: 54 957 / 11 < 5 000    (11)
  SALIX: 19 285 / 4 < 5 000       (4)
  ULMUS: 11 645 / 3 < 5 000       (3)
  
JÖNKÖPING:
  ALNUS: 42 217 / 9 < 5 000       (9)
  BETULA: 239 006 / 48 < 10 000   (48)
  CORYLUS: 3 594
  POACEAE: 31 676 / 7 < 5 000     (7)
  QUERCUS: 26 482 / 6 < 5 000     (6)
  SALIX: 13 929 / 3 < 5 000       (3)
  ULMUS: 4 884
  
MALMÖ:
  ALNUS: 31 596 / 7 < 5 000       (7)
  BETULA: 203 475 / 41 < 5 000    (41)
  CORYLUS: 4 562
  POACEAE: 87 912 / 18 < 5 000    (18)
  QUERCUS: 42 482 / 9 < 5 000     (9)
  SALIX: 17 940 / 4 < 5 000       (4)
  ULMUS: 35 560 / 8 < 5 000       (8)
  
NORRKÖPING:
  ALNUS: 24 089 / 5 < 5 000       (5)
  BETULA: 286 630 / 58 < 5 000    (58)
  CORYLUS: 4 484
  POACEAE: 50 537 / 11 < 5 000    (11)
  QUERCUS: 26 899 / 6 < 5 000     (6)
  SALIX: 14 715 / 3 < 5 000       (3)
  ULMUS: 6 509 / 2 < 5 000        (2)
  
STOCKHOLM:
  ALNUS: 55 346 / 12 < 5 000      (12)
  BETULA: 372 668 / 75 < 5 000    (75)
  CORYLUS: 5 848 / 2 < 5 000      (2)
  POACEAE: 52 569 / 11 < 5 000    (11)
  QUERCUS: 81 161 / 17 < 5 000    (17)
  SALIX: 15 398 / 4 < 5 000       (4)
  ULMUS: 33 284 / 7 < 5 000       (7)
  
UMEÅ:
  ALNUS: 16 454 / 4 < 5 000       (4)
  BETULA: 212 232 / 43 = 5 000    (43)
  CORYLUS: 113
  POACEAE: 22 639 / 5 < 5 000     (5)
  QUERCUS: 182
  SALIX: 8 875 / 2 < 5 000        (2)
  ULMUS: 167
  
VÄSTERVIK:
  ALNUS: 31 722 / 7 < 5 000       (7)
  BETULA: 231 147 / 24 < 10 000   (47)
  CORYLUS: 4 254
  POACEAE: 37 613 / 8 < 5 000     (8)
  QUERCUS: 40 942 / 9 < 5 000     (9)
  SALIX: 8 127 / 2 < 5 000        (2)
  ULMUS: 9 821 / 2 < 5 000        (2)





